{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"starting 4_save_synthetic_reference_images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook generates and saves the synthetic reference images. \n",
    "\n",
    "\n",
    "Large parts of this notebook are taken from https://github.com/bethgelab/testing_visualizations/blob/master/generate_stimuli/save_optimized_stimuli.py on 18.04.2021."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "import PIL\n",
    "import argparse\n",
    "\n",
    "# lucid imports\n",
    "import lucid.modelzoo.vision_models as models\n",
    "from lucid.optvis import transform\n",
    "import lucid.optvis.param as param\n",
    "\n",
    "# just modified render & objectives file and not the original files from lucid\n",
    "import render\n",
    "import objectives\n",
    "\n",
    "# custom imports\n",
    "import occlusion_utils as ut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import InceptionV1 from the Lucid modelzoo\n",
    "model = models.InceptionV1()\n",
    "model.load_graphdef()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-s\", \"--stimuli-dir\", required=True, help=\"Path to save stimuli to.\")\n",
    "parser.add_argument(\"-t\", \"--trial-type\", required=True, help=\"instruction_practice_catch or sampled_trials.\")\n",
    "args = parser.parse_args()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli_dir = args.stimuli_dir\n",
    "trial_type = args.trial_type\n",
    "_, _, batch_size_optimized = ut.get_number_of_stimuli(stimuli_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load experiment specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in unit specifications from csv into pandas dataframe\n",
    "path_to_csv_file = os.path.join(stimuli_dir, f\"layer_folder_mapping_{trial_type}.csv\")\n",
    "unit_specs_df = pd.read_csv(path_to_csv_file, header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_specs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_optimized_images_and_objectives(\n",
    "    max_or_min, images, objectives, loss_additional_global, destination_dir\n",
    "):\n",
    "    \"\"\"save the maximal optimized images\"\"\"\n",
    "    \n",
    "    # iterate over min and max\n",
    "    number_images = len(images)\n",
    "    for img_idx in range(number_images):\n",
    "        img = PIL.Image.fromarray(np.uint8(np.clip(images[img_idx] * 255, 0, 255)))\n",
    "        image_name = f\"reference_{max_or_min}_{img_idx}.png\"\n",
    "        image_path = os.path.join(destination_dir, image_name)\n",
    "        print(image_path)\n",
    "        img.save(image_path)\n",
    "\n",
    "    np.save(\n",
    "        os.path.join(destination_dir, f\"{max_or_min}_objective_values.npy\"),\n",
    "        objectives,\n",
    "    )\n",
    "    np.save(\n",
    "        os.path.join(\n",
    "            destination_dir,\n",
    "            f\"{max_or_min}_additional_global_diversity_loss.npy\",\n",
    "        ),\n",
    "        loss_additional_global,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_objective_stimuli(layer, feature_map):\n",
    "    img_size = 224\n",
    "\n",
    "    padding_size = 16\n",
    "    param_f = lambda: param.image(img_size + 2 * padding_size, batch=batch_size_optimized)\n",
    "    objective_per_image = objectives.channel(layer, feature_map)\n",
    "    diversity_loss = -1e2 * objectives.diversity(layer)\n",
    "\n",
    "    # transformations as described in Feature Visualization blog post\n",
    "    kwargs = dict(\n",
    "        thresholds=(2560,),\n",
    "        optimizer=tf.train.AdamOptimizer(learning_rate=0.05),\n",
    "        transforms=[\n",
    "            transform.jitter(16),\n",
    "            transform.random_scale((1.0, 0.975, 1.025, 0.95, 1.05)),\n",
    "            transform.random_rotate((-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5)),\n",
    "            transform.jitter(8),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # generate max stimuli\n",
    "    _, max_stimuli, max_loss, loss_additional_global_list = render.render_vis(\n",
    "        model,\n",
    "        objective_per_image,\n",
    "        diversity_loss,\n",
    "        param_f,\n",
    "        use_fixed_seed=True,\n",
    "        **kwargs,\n",
    "    )\n",
    "    # the optimization may save multiple states of the results\n",
    "    # the last item is the final value\n",
    "    max_stimuli = max_stimuli[-1]\n",
    "    max_loss = max_loss[-1]\n",
    "    max_loss_additional_global = loss_additional_global_list[-1]\n",
    "\n",
    "    # undo/crop padding\n",
    "    max_stimuli = max_stimuli[:, padding_size:-padding_size, padding_size:-padding_size]\n",
    "\n",
    "    return (\n",
    "        max_stimuli,\n",
    "        max_loss,\n",
    "        max_loss_additional_global,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the synthetic reference images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through each row\n",
    "for idx, cur_row in tqdm(unit_specs_df.iterrows(), total=len(unit_specs_df)):\n",
    "    start_time = time.time()\n",
    "    layer = f\"{cur_row['layer_name']}_{cur_row['pre_post_relu']}\"\n",
    "    feature_map = cur_row[\"feature_map_number\"]\n",
    "\n",
    "    (\n",
    "        max_stimuli,\n",
    "        max_loss,\n",
    "        max_loss_additional_global,\n",
    "    ) = get_channel_objective_stimuli(layer, feature_map)\n",
    "\n",
    "    # save images\n",
    "    destination_dir = os.path.join(\n",
    "            stimuli_dir,\n",
    "            ut.objective,\n",
    "            trial_type,\n",
    "            f\"layer_{cur_row['layer_number']}\",\n",
    "            f\"kernel_size_{cur_row['kernel_size_number']}\",\n",
    "            f\"channel_{cur_row['channel_number']}\",\n",
    "            \"optimized_images\",\n",
    "        )\n",
    "    os.makedirs(destination_dir, exist_ok=True)\n",
    "    save_optimized_images_and_objectives(\n",
    "        \"max\", max_stimuli, max_loss, max_loss_additional_global, destination_dir\n",
    "    )\n",
    "    print(f\"layer: {layer}, feature_map: {feature_map}, time = {time.time() - start_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"done with 4_save_synthetic_reference_images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
