{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Activations of ImageNet Subset - for ALL feature maps\n",
    "# ---all feature maps and target class saved in one file---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install lucid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !sudo pip3 install lucid==0.3.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy.ndimage as nd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lucid imports\n",
    "import lucid.modelzoo.vision_models as models\n",
    "from render import import_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom imports\n",
    "import occlusion_utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for debugging\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load experiment specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing and debugging\n",
    "objective_list = [\"channel\"]#, \"neuron\"]\n",
    "n_batches_stop = 1171\n",
    "stimuli_dir = \"$DATAPATH/all_activations_imagenet_train\" \n",
    "trial_type = \"sampled_trials\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import IneptionV1 from the Lucid modelzoo\n",
    "model = models.InceptionV1()\n",
    "model.load_graphdef()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_type = \"natural\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting seeds\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose parameters for data\n",
    "val_or_train = 'train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    \"\"\"\n",
    "\n",
    "    # override the __getitem__ method. this is the method dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ImageNet\n",
    "datapath = '$PATHTOIMAEGNET/'\n",
    "\n",
    "# get data\n",
    "data_dir = os.path.join(datapath, val_or_train)\n",
    "\n",
    "# make deterministic\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# preprocessing (corresponds to ResNet)\n",
    "this_dataset = ImageFolderWithPaths(data_dir, transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()\n",
    "    ]))\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    this_dataset,\n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, # TODO: determine shuffle! If images are determined over whole dataset, False is ok. Otherwise True.\n",
    "    num_workers=32, \n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(True)  # save memory and computation cost by not calculating the grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in unit specifications from csv into pandas dataframe\n",
    "path_to_csv_file = os.path.join(stimuli_dir, f\"layer_folder_mapping_{trial_type}.csv\")\n",
    "unit_specs_df = pd.read_csv(path_to_csv_file, header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ALL feature maps\n",
    "# make directories until layer-level\n",
    "for objective_i in objective_list:\n",
    "    for layer_number in range(10):\n",
    "        cur_dir = os.path.join(stimuli_dir, objective_i, \"sampled_trials\", f\"layer_{layer_number}\")\n",
    "        if not os.path.exists(cur_dir):\n",
    "            os.makedirs(cur_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'session' in locals() and session is not None:\n",
    "    print('Close interactive session')\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# for all but last batch\n",
    "# for ALL feature maps\n",
    "# different structure: csv saves list of values\n",
    "# for whole dataset: save relevant (according to neuron or channel objective) activation to csv\n",
    "with tf.Graph().as_default() as graph, tf.Session() as sess:\n",
    "    \n",
    "    image = tf.placeholder(tf.float32, shape=(batch_size, 224, 224, 3)) \n",
    "    model_instance = import_model(model, image)\n",
    "    tf_activations_list, unique_layer_str_list = ut.get_tf_activations_list_whole_net(model_instance, unit_specs_df)    \n",
    "\n",
    "    layer_dfs = [[] for _ in unique_layer_str_list]\n",
    "\n",
    "    # loop through batches\n",
    "    for batch_number, (images, targets, paths) in enumerate(tqdm(data_loader, total=len(data_loader.dataset) // batch_size)):\n",
    "        start_time = time.time()\n",
    "        if batch_number == n_batches_stop or batch_number == len(data_loader)-1:\n",
    "            last_batchs_batch_size = images.shape[0]\n",
    "            print(f\"breaking at {batch_number}\")\n",
    "            break\n",
    "        \n",
    "        # forward pass\n",
    "        images_np_transformed = images.numpy().transpose(0,2,3,1)\n",
    "        activations_list = sess.run(tf_activations_list, {image: images_np_transformed}) # batch_size, x, y, number_feature_maps\n",
    "\n",
    "        # save it!\n",
    "        # loop through layers\n",
    "        for layer_idx, cur_layer_str in enumerate(unique_layer_str_list):\n",
    "            activations_np = activations_list[layer_idx]\n",
    "            \n",
    "            # loop through objectives # TODO: remove after decision which objective to use\n",
    "            for objective_i in objective_list:\n",
    "                unit_activations = ut.get_activation_according_to_objective(objective_i, activations_np, np.arange(0,activations_np.shape[-1]))\n",
    "                unit_activations = unit_activations.astype(np.float16)\n",
    "                # write activation to csv\n",
    "                layer_dfs[layer_idx] += ut.create_unit_activations_dataset_rows(unit_activations, paths, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for layer_idx, layer_df in enumerate(layer_dfs):\n",
    "    layer_df = pd.DataFrame(layer_df)\n",
    "    activations_whole_dataset_csv = \"activations_whole_dataset.csv\"\n",
    "    activations_whole_dataset_pkl = \"activations_whole_dataset.pkl\"\n",
    "    layer_dir = os.path.join(stimuli_dir, objective_i, \"sampled_trials\", f\"layer_{layer_idx}\")\n",
    "    path_activations_whole_dataset_csv = os.path.join(layer_dir, activations_whole_dataset_csv)\n",
    "    path_activations_whole_dataset_pkl = os.path.join(layer_dir, activations_whole_dataset_pkl)\n",
    "    layer_df.to_csv(path_activations_whole_dataset_csv)\n",
    "    layer_df.to_pickle(path_activations_whole_dataset_pkl)\n",
    "\n",
    "print('Done!!!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}