{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"starting C_get_labels_of_natural_reference_and_default_images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook saves ut.n_batches of ut.n_bins (== batch-size) most strongly activating images as well as the default ImageNet images for the occlusion stimuli on share.\n",
    "\n",
    "Large parts of this notebook are taken from https://github.com/bethgelab/testing_visualizations/blob/master/generate_stimuli/save_natural_stimuli.py on 14.04.2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import ast\n",
    "import time\n",
    "from torch.utils import data\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision.datasets.folder import default_loader as default_image_loader\n",
    "from torchvision import transforms\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import occlusion_utils as ut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_max_filename = \"activation_max.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_args = \"-s=$PATHTOGENERATEDSTIMULI/stimuli_pure_conditions -t sampled_trials\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-s\", \"--stimuli-dir\", required=True, help=\"Path to save stimuli to.\")\n",
    "parser.add_argument(\"-t\", \"--trial-type\", required=True, help=\"instruction_practice_catch or sampled_trials.\")\n",
    "args = parser.parse_args(raw_args.split(\" \"))\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli_dir = args.stimuli_dir\n",
    "trial_type = args.trial_type\n",
    "n_reference_images, n_bins, _ = ut.get_number_of_stimuli(stimuli_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in units (layer, kernel_size, feature map) of interest\n",
    "# this is the list of units we used in the MTurk CFV experiment\n",
    "from io import StringIO\n",
    "csv_data = StringIO(\"\"\"\n",
    "#\n",
    "layer_number,kernel_size_number,channel_number,layer_name,pre_post_relu,kernel_size,feature_map_number\n",
    "0,1,0,mixed3a,pre_relu,3x3,189\n",
    "1,1,0,mixed3b,pre_relu,3x3,178\n",
    "2,1,0,mixed4a,pre_relu,3x3,257\n",
    "3,1,0,mixed4b,pre_relu,3x3,339\n",
    "4,1,0,mixed4c,pre_relu,3x3,247\n",
    "5,1,0,mixed4d,pre_relu,3x3,342\n",
    "6,1,0,mixed4e,pre_relu,3x3,524\n",
    "7,1,0,mixed5a,pre_relu,3x3,278\n",
    "8,1,0,mixed5b,pre_relu,3x3,684\n",
    "0,3,0,mixed3a,pre_relu,pool,227\n",
    "1,3,0,mixed3b,pre_relu,pool,430\n",
    "2,3,0,mixed4a,pre_relu,pool,486\n",
    "3,3,0,mixed4b,pre_relu,pool,491\n",
    "4,3,0,mixed4c,pre_relu,pool,496\n",
    "5,3,0,mixed4d,pre_relu,pool,483\n",
    "6,3,0,mixed4e,pre_relu,pool,816\n",
    "7,3,0,mixed5a,pre_relu,pool,743\n",
    "8,3,0,mixed5b,pre_relu,pool,1007\n",
    "\"\"\")\n",
    "unit_specs_df = pd.read_csv(csv_data, header=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_randomized_indices_except_for_last_bin(n_bins, n_batches, seed):\n",
    "    \"\"\"generate randomized order of indices except for the last bin.\n",
    "    This means that for all but the last bin the 20 images that belong to one \n",
    "    bin (e.g. min_0.png) is different:\n",
    "    randomize(0...19), then randomize(20...39) ... randomize(160...179).\n",
    "    The last bin stays in order: (180 181 182 ... 199).\n",
    "    Use this function for between-subject designs!!!\n",
    "    \"\"\"\n",
    "    randomized_indices = np.empty([n_bins * n_batches])\n",
    "    array_of_n_batches = np.arange(n_batches)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    for bin_i in range(n_bins):\n",
    "        # keep the order of the largest indices in order\n",
    "        if bin_i == n_bins - 1:\n",
    "            randomized_indices[\n",
    "                (n_batches * bin_i) : (n_batches + bin_i * n_batches)\n",
    "            ] = array_of_n_batches + bin_i * n_batches\n",
    "        # permute the order of all but the largest indices\n",
    "        else:\n",
    "            randomized_indices[\n",
    "                (n_batches * bin_i) : (n_batches + bin_i * n_batches)\n",
    "            ] = np.random.permutation(array_of_n_batches + bin_i * n_batches)\n",
    "\n",
    "    return randomized_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy images over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names_number_dict = {\n",
    "    'mixed3a': 0,\n",
    "    'mixed3b': 1,\n",
    "    'mixed4a': 2,\n",
    "    'mixed4b': 3,\n",
    "    'mixed4c': 4,\n",
    "    'mixed4d': 5,\n",
    "    'mixed4e': 6,\n",
    "    'mixed5a': 7,\n",
    "    'mixed5b': 8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_paths = []\n",
    "\n",
    "# iterate over dataframe\n",
    "for _, row in tqdm(unit_specs_df.iterrows()):\n",
    "    start = time.time()\n",
    "    kernel_size = row[\"kernel_size_number\"]\n",
    "    channel_number = row[\"channel_number\"]\n",
    "    feature_map = row[\"feature_map_number\"]\n",
    "    layer_number = row[\"layer_number\"]\n",
    "    layer_name = row[\"layer_name\"]\n",
    "    print(f\"layer_name {layer_name}, feature_map {feature_map}, channel {channel_number}, kernel_size {kernel_size}\")\n",
    "    \n",
    "    # folder where csv with activations for all 50,000 images is stored\n",
    "    csv_filename = f\"$DATAPATH/all_activations_imagenet_train/channel/sampled_trials/layer_{layer_names_number_dict[layer_name]}/activations_whole_dataset.pkl\"\n",
    "    \n",
    "    # load this csv into df (takes long!)\n",
    "    print(\"Loading df\")\n",
    "    # df = pd.read_csv(csv_filename, header=1, converters={'activation': ast.literal_eval})\n",
    "    df = pd.read_pickle(csv_filename)\n",
    "    \n",
    "    print(\"df loaded\")\n",
    "    \n",
    "    # select relevant feature map and sort in descending order\n",
    "    df_expanded = df.copy()\n",
    "    df_expanded[\"selected_activation\"] = df[\"activation\"].apply(lambda x: x[feature_map])\n",
    "    df_expanded_sorted = df_expanded.sort_values(\"selected_activation\", ascending=True)\n",
    "    \n",
    "    # create dataframes with relevant columns and rows only. Also, randomize the order in one image bin\n",
    "    assert n_bins <= 10, \"n_bins is upper bounded by 10\"\n",
    "\n",
    "    # generate indices always under the assumption that we need 10 bins\n",
    "    max_indices = get_randomized_indices_except_for_last_bin(\n",
    "        10, ut.n_batches, seed=feature_map + 1\n",
    "    )\n",
    "    # then only use last n_bins bins and shift their index values\n",
    "    max_indices = max_indices[-n_bins*ut.n_batches:] - ((10 - n_bins) * ut.n_batches)\n",
    "    max_images_activations_df = (\n",
    "        df_expanded_sorted[-n_bins * ut.n_batches :]\n",
    "        .drop([\"activation\", \"target class\"], axis=1)\n",
    "        .iloc[max_indices]\n",
    "    )\n",
    "    \n",
    "    # load dataset\n",
    "    max_file_names = max_images_activations_df[\"path to image\"].tolist()\n",
    "    \n",
    "    image_paths = [{'references': []} for _ in range(ut.n_batches)]\n",
    "    \n",
    "    for image_idx_in_batch in range(n_bins):\n",
    "        for batch in range(ut.n_batches):\n",
    "            image_idx = batch + ut.n_batches * image_idx_in_batch\n",
    "\n",
    "\n",
    "            # save image\n",
    "            max_image_path = max_file_names[image_idx]\n",
    "            \n",
    "            if image_idx_in_batch == n_reference_images:\n",
    "                # query image\n",
    "                image_paths[batch][\"query_image_path\"] = max_image_path          \n",
    "            else:\n",
    "                image_paths[batch][\"references\"].append(max_image_path)\n",
    "           \n",
    "                \n",
    "    all_image_paths.append(image_paths)\n",
    "    end = time.time()\n",
    "    print(f\"       time for one layer: {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [it for lst in all_image_paths for it in lst[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"finished C_get_labels_of_natural_reference_and_default_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_wordnet_ids = []\n",
    "for item in image_paths:\n",
    "    image_wordnet_ids.append({\n",
    "        \"references\": [a.replace(\"$PATHTOIMAEGNET/train/\", \"\").split(\"/\")[0] for a in item[\"references\"]],\n",
    "        \"query_image\": item[\"query_image_path\"].replace(\"$PATHTOIMAEGNET/train/\", \"\").split(\"/\")[0],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in image_wordnet_ids:\n",
    "    n_same = sum([ref == item[\"query_image\"] for ref in item[\"references\"]])\n",
    "    item[\"n_same_labels\"] = n_same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.array([item[\"n_same_labels\"] for item in image_wordnet_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams[\"font.family\"] = \"sans-serif\"\n",
    "rcParams[\"font.sans-serif\"] = [\"DejaVu Sans\"]\n",
    "\n",
    "# output text as text and not paths\n",
    "rcParams[\"svg.fonttype\"] = \"none\"\n",
    "rcParams[\"pdf.fonttype\"] = \"truetype\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_type = \".pdf\"\n",
    "fontsize_axes_labels = 10\n",
    "fontsize_tick_labels = 8\n",
    "x_tick_label_rotation = 30\n",
    "error_bar_linewidth = 1\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bins_labels(bins, **kwargs):\n",
    "    bin_w = (max(bins) - min(bins)) / (len(bins) - 1)\n",
    "    plt.xticks(np.arange(min(bins)+bin_w/2, max(bins), bin_w), bins, **kwargs)\n",
    "    plt.xlim(bins[0]-0.25, bins[-1]+0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bins = np.arange(11)\n",
    "hist = plt.hist(counts, bins=bins, rwidth=0.9)\n",
    "bins_labels(bins)\n",
    "plt.xlabel(\"#Reference images w/ same label as query images\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "# no axis on top and right\n",
    "plt.gca().spines[\"top\"].set_visible(False)\n",
    "plt.gca().spines[\"right\"].set_visible(False)\n",
    "\n",
    "plt.savefig(\"reference_query_labels_histogram.pdf\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
