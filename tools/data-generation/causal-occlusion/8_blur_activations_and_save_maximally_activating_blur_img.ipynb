{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"starting 8_blur_activations_and_save_maximally_activating_blur_img\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate Occlusion Stimuli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# general imports\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import copy\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lucid imports\n",
    "import lucid.modelzoo.vision_models as models\n",
    "from render import import_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom imports\n",
    "import occlusion_utils as ut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import InceptionV1 from the Lucid modelzoo\n",
    "model = models.InceptionV1()\n",
    "model.load_graphdef()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_forward_pass = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting seeds\n",
    "tf.set_random_seed(1234)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-s\", \"--stimuli-dir\", required=True, help=\"Path to save stimuli to.\")\n",
    "parser.add_argument(\"-t\", \"--trial-type\", required=True, help=\"instruction_practice_catch or sampled_trials.\")\n",
    "args = parser.parse_args()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli_dir = args.stimuli_dir\n",
    "trial_type = args.trial_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: test with this cell, then change the upper two cells back\n",
    "# stimuli_dir = \"$DATAPATH/stimuli/stimuli_pure_conditions\"\n",
    "# trial_type = \"sampled_trials\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load experiment specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in unit specifications from csv into pandas dataframe\n",
    "path_to_csv_file = os.path.join(stimuli_dir, f\"layer_folder_mapping_{trial_type}.csv\")\n",
    "unit_specs_df = pd.read_csv(path_to_csv_file, header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unit_specs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop over all layers\n",
    "for _, row in tqdm(unit_specs_df.iterrows(), unit=\"row\", total=len(unit_specs_df), position=0):\n",
    "    # load unit specification\n",
    "    layer_number = row[\"layer_number\"]\n",
    "    kernel_size_number = row[\"kernel_size_number\"]\n",
    "    channel_number = row[\"channel_number\"]\n",
    "    feature_map_number = row[\"feature_map_number\"]\n",
    "    layer_name = row[\"layer_name\"]\n",
    "    pre_post_relu = row[\"pre_post_relu\"]\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # dataloader\n",
    "    data_dir = os.path.join(\n",
    "        stimuli_dir,\n",
    "        ut.objective,\n",
    "        trial_type,\n",
    "        f\"layer_{layer_number}\",\n",
    "        f\"kernel_size_{kernel_size_number}\",\n",
    "        f\"channel_{channel_number}\",\n",
    "        \"natural_images\",\n",
    "    )\n",
    "\n",
    "    data_loader = ut.get_data_loader(data_dir, do_resize_and_center_crop=False)\n",
    "\n",
    "    # loop over all occlusion sizes\n",
    "    for heatmap_size_i, occlusion_size_i, percentage_side_length_i in zip(ut.heatmap_sizes_list,\n",
    "                                                                          ut.occlusion_sizes_list,\n",
    "                                                                          ut.percentage_side_length_list):\n",
    "\n",
    "        if percentage_side_length_i != 40:\n",
    "            continue\n",
    "        print(\"Patch Size:\", percentage_side_length_i)\n",
    "\n",
    "        list_of_positions = ut.get_list_of_occlusion_positions(heatmap_size_i, occlusion_size_i)\n",
    "\n",
    "        if 'session' in locals() and session is not None:\n",
    "            print('Close interactive session')\n",
    "            session.close()\n",
    "\n",
    "        with tf.Graph().as_default() as graph, tf.Session() as sess:\n",
    "\n",
    "            image = tf.placeholder(tf.float32, shape=(batch_size_forward_pass, 224, 224, 3))\n",
    "\n",
    "            model_instance = import_model(model, image)\n",
    "            tf_activations_list, unique_layer_str_list = ut.get_tf_activations_list(model_instance, layer_name, pre_post_relu)\n",
    "\n",
    "            # loop over all images in all batches\n",
    "            for images, targets, paths in tqdm(data_loader, leave=False, position=1, unit=\"image\", total=len(data_loader.dataset)):\n",
    "                # only evaluate reference images, no query images\n",
    "                if \"reference_max\" not in paths[0]:\n",
    "                    continue\n",
    "\n",
    "                batch_name = Path(paths[0]).parts[-2]\n",
    "\n",
    "                destination_dir = os.path.join(\n",
    "                    stimuli_dir,\n",
    "                    ut.objective,\n",
    "                    trial_type,\n",
    "                    f\"layer_{layer_number}\",\n",
    "                    f\"kernel_size_{kernel_size_number}\",\n",
    "                    f\"channel_{channel_number}\",\n",
    "                    \"natural_blur_images\",\n",
    "                    f\"{batch_name}\"\n",
    "                )\n",
    "                destination_dir = os.path.join(\n",
    "                    destination_dir,\n",
    "                    f\"{percentage_side_length_i}_percent_side_length\"\n",
    "                )\n",
    "\n",
    "                os.makedirs(destination_dir, exist_ok=True)\n",
    "                final_image_path = os.path.join(destination_dir, f\"blurred_{os.path.basename(paths[0]).split('.png')[0]}.png\")\n",
    "\n",
    "                if os.path.exists(final_image_path):\n",
    "                    continue\n",
    "\n",
    "                # iterate over all occlusion positions for the current image\n",
    "                list_of_activations_for_occlusions = []\n",
    "                n_iterations = math.ceil(len(list_of_positions) / batch_size_forward_pass)\n",
    "                for iteration_i in tqdm(list(range(n_iterations)), unit=\"position\", leave=False, position=2):\n",
    "                    cur_list_of_positions = list_of_positions[iteration_i*batch_size_forward_pass:\n",
    "                                                              iteration_i*batch_size_forward_pass+batch_size_forward_pass]\n",
    "\n",
    "                    # forward pass\n",
    "                    images_np_transformed = images.numpy().transpose(0,2,3,1) # (1, 224, 224, 3)\n",
    "                    images_np_transformed_copied = copy.deepcopy(images_np_transformed)\n",
    "                    images_np_transformed_ready_for_occlusion = np.tile(images_np_transformed_copied, (batch_size_forward_pass, 1, 1, 1)) # (batch_size_forward_pass, 224, 224, 3)\n",
    "\n",
    "                    # loop through occlusion positions\n",
    "                    for idx, (x_start, x_end, y_start, y_end) in enumerate(cur_list_of_positions):\n",
    "                        patch_to_keep = images_np_transformed_copied[0, x_start:x_end, y_start:y_end, :]\n",
    "                        images_np_transformed_ready_for_occlusion[idx, :, :, :] = cv2.GaussianBlur(images_np_transformed_ready_for_occlusion[idx], (21,21), 0)\n",
    "                        images_np_transformed_ready_for_occlusion[idx, x_start:x_end, y_start:y_end, :] = patch_to_keep\n",
    "\n",
    "                    activations_list = sess.run(tf_activations_list, {image: images_np_transformed_ready_for_occlusion})\n",
    "\n",
    "                    # unpack single list item\n",
    "                    activations_np = activations_list[0]\n",
    "                    unit_activations = ut.get_activation_according_to_objective(ut.objective, activations_np, feature_map_number)\n",
    "                    list_of_activations_for_occlusions.append(list(unit_activations))\n",
    "\n",
    "                # after having calculated all occlusions: save activations\n",
    "                final_list_of_activations_for_occlusions = [item for sublist in list_of_activations_for_occlusions for item in sublist]\n",
    "\n",
    "                filename = os.path.join(destination_dir, f\"activations_for_occlusions_of_{percentage_side_length_i}_percent_{os.path.basename(paths[0]).split('.png')[0]}.npy\")\n",
    "                activations_data_one_occlusion_size = final_list_of_activations_for_occlusions[:len(list_of_positions)+1]\n",
    "                np.save(filename, activations_data_one_occlusion_size)\n",
    "\n",
    "                # save image of maximal activation with blur\n",
    "                extreme_idx = np.argmax(activations_data_one_occlusion_size[:-1])\n",
    "                x_start, x_end, y_start, y_end = list_of_positions[extreme_idx]\n",
    "\n",
    "                image_to_be_saved = copy.deepcopy(images_np_transformed.squeeze())\n",
    "                image_to_be_saved_for_patch = copy.deepcopy(image_to_be_saved)\n",
    "                patch_to_keep = image_to_be_saved_for_patch[x_start:x_end, y_start:y_end, :]\n",
    "                image_to_be_saved[:, :, :] = cv2.GaussianBlur(image_to_be_saved, (21,21), 0)\n",
    "                image_to_be_saved[x_start:x_end, y_start:y_end, :] = patch_to_keep\n",
    "\n",
    "                cv2.imwrite(final_image_path, cv2.cvtColor(image_to_be_saved*255, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    print(\"Completely done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"done with 8_blur_activations_and_save_maximally_activating_blur_img\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}